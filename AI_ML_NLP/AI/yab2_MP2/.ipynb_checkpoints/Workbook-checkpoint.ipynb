{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yashasab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "import argparse\n",
    "import configparser\n",
    "import copy\n",
    "import reader\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk.lm import NgramCounter\n",
    "from nltk import word_tokenize \n",
    "nltk.download('punkt')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 418.47it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 318.57it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 342.37it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 283.20it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels, dev_set, dev_labels = reader.load_dataset('data/spam_data/train','data/spam_data/dev', 'stemming', 'lower_case' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lol': 2, 'lolly': 3}, {'lodl': 5, 'ggg': 4}]\n"
     ]
    }
   ],
   "source": [
    "a = { 'lol' : 2, 'lolly' : 3}\n",
    "\n",
    "b = {'lodl' : 5, 'ggg' : 4}\n",
    "\n",
    "x = [a,b]\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b2241216421e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0midf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnumdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def EXCRED(train_set, train_labels, dev_set):\n",
    "    wordcounts = NgramCounter()\n",
    "\n",
    "    dcount = {}\n",
    "\n",
    "    highest=[]\n",
    "\n",
    "    numdocs = len(train_set)\n",
    "\n",
    "    for i in range(0,train_labels.shape[0]):\n",
    "        message = ' '.join(x for x in train_set[i])\n",
    "        wordcounts =  NgramCounter([ngrams(word_tokenize(message), 1)])\n",
    "\n",
    "        for word in wordcounts[1].keys():\n",
    "\n",
    "            x = dcount.get(word, -1)\n",
    "\n",
    "            if x < 1:\n",
    "                dcount[word] = 1\n",
    "            else:\n",
    "                y = dcount[word]\n",
    "                dcount[word] = y+1\n",
    "\n",
    "\n",
    "    for mes in dev_set:\n",
    "        message = ' '.join(x for x in mes)\n",
    "        wordcounts =  NgramCounter([ngrams(word_tokenize(message), 1)])\n",
    "        tf = {}\n",
    "        numwords = wordcounts[1].N()   \n",
    "\n",
    "        for word in wordcounts[1].keys():\n",
    "\n",
    "            idf = dcount.get(word, 0)\n",
    "            \n",
    "            tf[word] = (wordcounts[word]/numwords) * np.log10(numdocs/(1+idf))\n",
    "\n",
    "        high = max(tf, key=tf.get) \n",
    "\n",
    "        highest.append(high)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yashasab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 4284.71it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 4085.25it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 4018.64it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3495.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished executing compute_tf_idf()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%run mp2_tf_idf.py --training data/spam_data/train --development data/spam_data/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 397.86it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 320.27it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 335.77it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 292.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.961\n",
      "F1-Score: 0.961576354679803\n",
      "Precision: 0.9475728155339805\n",
      "Recall: 0.976\n"
     ]
    }
   ],
   "source": [
    "%run mp2_mixture.py --training data/spam_data/train --development data/spam_data/dev --stemming False --lower_case True --bigram_lambda=0.5 --unigram_smoothing=0.1 --bigram_smoothing=0.1 --pos_prior 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running unigram test...\n",
      "\n",
      "Accuracy: 0.953\n",
      "F1-Score: 0.9542356377799417\n",
      "Precision: 0.9297912713472486\n",
      "Recall: 0.98\n",
      "+ 5 points for accuracy  above 0.81\n",
      "+ 5 points for accuracy above 0.86\n",
      "+ 5 points for accuracy above 0.91\n",
      "+ 5 points for accuracy above 0.95\n",
      "\n",
      "{\n",
      " \"name\": \"Unigram test on dev set without stemming and without lowercase\",\n",
      " \"score\": 20,\n",
      " \"max_score\": 20,\n",
      " \"visibility\": \"visible\"\n",
      "}\n",
      "\n",
      "Running mixture model test...\n",
      "\n",
      "Accuracy: 0.932\n",
      "F1-Score: 0.9351145038167938\n",
      "Precision: 0.8941605839416058\n",
      "Recall: 0.98\n",
      "+ 1.25 points for accuracy  above 0.8\n",
      "+ 1.25 points for accuracy above 0.85\n",
      "+ 1.25 points for accuracy above 0.9\n",
      "Accuracy needs to be above 0.95\n",
      "We hypothesize that your implementation of naiveBayesMixture is not correct. Therefore, we applied a penalty multiplier of 0.25 to your score.\n",
      "\n",
      "{\n",
      " \"name\": \"Mixture test on dev set without stemming and without lowercase\",\n",
      " \"score\": 0.9375,\n",
      " \"max_score\": 5,\n",
      " \"visibility\": \"visible\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run grade.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hamcounts = NgramCounter()\n",
    "\n",
    "\n",
    "spamcounts = NgramCounter()\n",
    "\n",
    "totalcounts = NgramCounter()\n",
    "\n",
    "\n",
    "for i in range(0,train_labels.shape[0]):\n",
    "\n",
    "    message = ' '.join(x for x in train_set[i])\n",
    "    if train_labels[i]==1:\n",
    "        hamcounts.update([ngrams(word_tokenize(message), 1)])\n",
    "\n",
    "    if train_labels[i]==0:\n",
    "        spamcounts.update([ngrams(word_tokenize(message), 1)])\n",
    "\n",
    "    totalcounts.update([ngrams(word_tokenize(message), 1)])\n",
    "    \n",
    "    \n",
    "predicts = []\n",
    "\n",
    "s = time.time()\n",
    "    \n",
    "num = 0\n",
    "for mes in dev_set:\n",
    "    \n",
    "    pham = 0\n",
    "    pspam = 0\n",
    "\n",
    "    for word in mes:\n",
    "        \n",
    "        hlike = (hamcounts[word]+sp)/(hamcounts.N()+(sp*hamcounts[1].B()))\n",
    "        \n",
    "        slike = (spamcounts[word]+sp)/(spamcounts.N()+(sp*spamcounts[1].B()))\n",
    "        \n",
    "        pham = pham + np.log(hlike)\n",
    "        \n",
    "        pspam = pspam + np.log(slike)\n",
    "    \n",
    "    pham = pham + np.log(prior)\n",
    "    \n",
    "    pspam = pspam + np.log(1-prior)\n",
    "    \n",
    "    if pspam>pham:\n",
    "        predicts.append(0)\n",
    "    else:\n",
    "        predicts.append(1)\n",
    "    num = num+1\n",
    "e = time.time()\n",
    "print('time for analyzing ', num , 'msgs ', e-s)    \n",
    "predicted_labels = np.asarray(predicts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final working output of Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken  4.794314861297607\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bsp = 0.1\n",
    "\n",
    "usp = 0.1\n",
    "\n",
    "prior = 0.5\n",
    "\n",
    "lamda = 0.5\n",
    "\n",
    "bhamcounts = NgramCounter()\n",
    "\n",
    "bspamcounts = NgramCounter()\n",
    "\n",
    "hamcounts = NgramCounter()\n",
    "\n",
    "\n",
    "spamcounts = NgramCounter()\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "Hcunt = {}\n",
    "Scunt = {}\n",
    "\n",
    "for i in range(0,train_labels.shape[0]):\n",
    "\n",
    "    message = ' '.join(x for x in train_set[i])\n",
    "    if train_labels[i]==1:\n",
    "        \n",
    "        hamcounts.update([ngrams(word_tokenize(message), 1)])\n",
    "        bhamcounts.update([ngrams(word_tokenize(message), 2)])\n",
    "        \n",
    "\n",
    "    if train_labels[i]==0:\n",
    "        \n",
    "        spamcounts.update([ngrams(word_tokenize(message), 1)])\n",
    "        bspamcounts.update([ngrams(word_tokenize(message), 2)])\n",
    "        \n",
    "bhden = bhamcounts[2].N()+(bsp*len(bhamcounts[2].conditions()))\n",
    "bsden = bspamcounts[2].N()+(bsp*len(bspamcounts[2].conditions()))\n",
    "\n",
    "biprob = []\n",
    "\n",
    "for mes in dev_set:\n",
    "    \n",
    "    pham = 0\n",
    "    pspam = 0\n",
    "    \n",
    "    msg = ' '.join(x for x in mes)\n",
    "\n",
    "    for bi in ngrams(word_tokenize(msg), 2):\n",
    "        \n",
    "        h = Hcunt.get((bi[0],bi[1]), -1)\n",
    "        \n",
    "        if h>= 0:\n",
    "            hlike = Hcunt[bi[0], bi[1]]\n",
    "            \n",
    "        else: \n",
    "            hcount = bhamcounts[[bi[0]]][bi[1]]\n",
    "            hlike = (hcount+bsp)/(bhden)\n",
    "            Hcunt[bi[0], bi[1]] = hlike\n",
    "        \n",
    "        s = Scunt.get((bi[0],bi[1]), -1)\n",
    "        \n",
    "        if s>= 0:\n",
    "            slike = Scunt[bi[0], bi[1]]\n",
    "        else: \n",
    "            scount = bspamcounts[[bi[0]]][bi[1]]\n",
    "            slike = (scount+bsp)/(bsden)\n",
    "            Scunt[bi[0], bi[1]] = slike\n",
    "        \n",
    "        pham = pham + np.log(hlike)\n",
    "        \n",
    "        pspam = pspam + np.log(slike)\n",
    "        \n",
    "    \n",
    "    \n",
    "    pham = pham + (np.log(prior) * lamda)\n",
    "    \n",
    "    pspam = pspam + (np.log(1-prior) * lamda)\n",
    "    \n",
    "    biprob.append((pham, pspam))\n",
    "    \n",
    "    \n",
    "uprob = uniprobs(hamcounts, spamcounts, dev_set[:10], usp, prior, lamda)\n",
    "\n",
    "predicts = []\n",
    "\n",
    "for i in range(0, uprob.shape[0]):\n",
    "    \n",
    "    pham = uprob[i][0] + biprob[i][0]\n",
    "    \n",
    "    pspam = uprob[i][1] + biprob[i][1]\n",
    "    \n",
    "    if pspam>pham:\n",
    "        predicts.append(0)\n",
    "    else:\n",
    "        predicts.append(1)\n",
    "\n",
    "e= time.time()\n",
    "\n",
    "print('time taken ' , e-st)\n",
    "predicted_labels = np.asarray(predicts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# return probabilities of unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniprobs(hamcounts, spamcounts, dev_set, usp, prior, lamda):\n",
    "    \n",
    "\n",
    "    probs = []\n",
    "\n",
    "    hden = hamcounts.N()+(usp*hamcounts[1].B())\n",
    "    sden = spamcounts.N()+(usp*spamcounts[1].B())\n",
    "\n",
    "    num = 0\n",
    "    for mes in dev_set:\n",
    "\n",
    "        pham = 0\n",
    "        pspam = 0\n",
    "\n",
    "        for word in mes:\n",
    "\n",
    "            hlike = (hamcounts[word]+usp)/(hden)\n",
    "\n",
    "            slike = (spamcounts[word]+usp)/(sden)\n",
    "\n",
    "            pham = pham + np.log(hlike)\n",
    "\n",
    "            pspam = pspam + np.log(slike)\n",
    "\n",
    "        pham = pham + (np.log(prior) * (1-lamda))\n",
    "\n",
    "        pspam = pspam + (np.log(1-prior) *(1-lamda))\n",
    "        \n",
    "        probs.append((pham,pspam))\n",
    "        \n",
    "    p = np.asarray(probs)\n",
    "   \n",
    "    \n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
