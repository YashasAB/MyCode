{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (viterbi_ec.py, line 137)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/Users/yashasab/Desktop/yab2_mp4/viterbi_ec.py\"\u001b[0;36m, line \u001b[0;32m137\u001b[0m\n\u001b[0;31m    print(suff[s])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%run mp4.py --train data/brown-training.txt --test data/brown-dev.txt --algorithm viterbi_ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.00001\n",
    "    words = {}\n",
    "    types = Counter()\n",
    "    pairprob = {}\n",
    "    output = []\n",
    "    suffix = ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']\n",
    "    \n",
    "    suff = {}\n",
    "    \n",
    "    for s in suffix:\n",
    "        suff[s] = wcount()\n",
    "    for sent in train:\n",
    "        \n",
    "        prev = ''\n",
    "        \n",
    "        for i in range(0, len(sent)):\n",
    "            \n",
    "            w,t = sent[i]\n",
    "            \n",
    "            types.update([t])\n",
    "            \n",
    "            if i ==0:\n",
    "                \n",
    "                prev = 'START'\n",
    "                \n",
    "            else:\n",
    "                pairs = pairprob.get(prev, -1)\n",
    "                \n",
    "                if pairs== -1:\n",
    "                    a = wcount()\n",
    "                    a.addtag(t)\n",
    "                    pairprob[prev] = a\n",
    "                else:\n",
    "                    pairs.addtag(t)\n",
    "                \n",
    "                prev = t\n",
    "                                      \n",
    "            #tcount is counter with number of times each tag occured for a given word\n",
    "            tcount = words.get(w, -1)\n",
    "            \n",
    "            if tcount==-1:\n",
    "                a = wcount()\n",
    "                a.addtag(t)\n",
    "                words[w] = a\n",
    "                for s in suffix:\n",
    "                    if w.endswith(s):\n",
    "                        suff[s].addtag(t)\n",
    "                \n",
    "            else:\n",
    "                tcount.addtag(t)\n",
    "                for s in suffix:\n",
    "                    if w.endswith(s):\n",
    "                        suff[s].addtag(t)\n",
    "                \n",
    "#     training is done, predicting below\n",
    "    tags = []\n",
    "    for t in types.keys():\n",
    "        tags.append(t) \n",
    "        \n",
    "    tags.remove('START')\n",
    "    \n",
    "    lentags = len(tags)\n",
    "    \n",
    "    for t in tags:   \n",
    "        pairprob['START'].probs[t] = np.log((pairprob['START'].tags[t] + alpha) / (types['START'] + len(tags) * alpha))\n",
    "    \n",
    "    hxprob = wcount()\n",
    "    hxwords = 0\n",
    "    \n",
    "    \n",
    "    for word in words.keys():        \n",
    "        if sum(words[word].tags.values()) == 1:\n",
    "            t = words[word].maxtag()            \n",
    "            hxprob.addtag(t)\n",
    "            hxwords += 1\n",
    "    \n",
    "    thapax = hxwords\n",
    "      \n",
    "    for t in tags:\n",
    "        hxprob.probs[t] = np.log((hxprob.tags[t]+alpha)/(thapax+(alpha*(lentags+1))))\n",
    "        \n",
    "    \n",
    "    for i in range(0, len(tags)):\n",
    "        if tags[i] not in pairprob.keys():\n",
    "            a = wcount()\n",
    "            for t in tags:\n",
    "                a.probs[t]=np.log(alpha / (types[t] + (alpha*(lentags+1))))            \n",
    "            pairprob[tags[i]] = a\n",
    "        else:\n",
    "            for t in tags:\n",
    "                pairprob[tags[i]].probs[t]=np.log((pairprob[tags[i]].tags[t] + alpha) / (types[t] + (alpha*(lentags+1))))   \n",
    "                               \n",
    "    endprobs = calcendprobs(pairprob, tags)\n",
    "    \n",
    "#         create nodes for all tags\n",
    "    nodes = []\n",
    "    for t in tags:\n",
    "        n = tnode()\n",
    "        nodes.append(n)\n",
    "        \n",
    "    lenwords = len(words.keys())\n",
    "    \n",
    "    wprobs={}\n",
    "    \n",
    "    for s in suffix:\n",
    "        for t in tags:\n",
    "            suff[s].probs[t]=np.log((suff[s].tags[t] + alpha) / (types[t] + (alpha*(lentags+1))))\n",
    "            print(suff[s])\n",
    "    for sent in test:\n",
    "        trell = trellis(nodes)\n",
    "        unseennum = []\n",
    "        unseenadj = []\n",
    "        \n",
    "        for i in range(1, len(sent)-1):\n",
    "                    \n",
    "            w = sent[i]\n",
    "            \n",
    "            p = wprobs.get(w,-1)\n",
    "            \n",
    "            if p==-1:\n",
    "                x = words.get(w, -1)\n",
    "                if x == -1:\n",
    "                    pro = {}\n",
    "                    for t in tags:\n",
    "                        pro[t] = hxprob.probs[t] + np.log((alpha / (types[t] + (lentags+1)*alpha)))\n",
    "                    wprobs[w] = pro\n",
    "                    if len(w) < 2:\n",
    "                        if w[0].isdigit():\n",
    "                            unseennum.append(i)\n",
    "                    else:\n",
    "                        if w[0]=='$':\n",
    "                            unseennum.append(i)\n",
    "                        elif w[0].isdigit():\n",
    "                            if w[1].isdigit() or w[1] == '.':\n",
    "                                unseennum.append(i)\n",
    "                            else:\n",
    "                                unseenadj.append(i)\n",
    "                        else:\n",
    "                            for s in suffix:\n",
    "                                if w.endswith(s):\n",
    "                                    for t in tags:\n",
    "                                        suff[s].probs[t] = hxprob.probs[t] + np.log((suff[s].tags[t] + alpha) / (types[t] +(lenwords+1)*alpha))\n",
    "                                    wprobs[w] = suff[s].probs\n",
    "                                    break\n",
    "                                    \n",
    "                                       \n",
    "                            \n",
    "                else:\n",
    "                    for t in tags:\n",
    "                        x.probs[t] = np.log((x.tags[t] + alpha) / (types[t] + (lenwords+1)*alpha))                    \n",
    "                    wprobs[w] = x.probs\n",
    "                    \n",
    "            #now p has the word dict- keys = tags, val = prob that word has that tag\n",
    "            if i ==1:\n",
    "                #if dealing with first word of sentance. trell.prevs nodes should have start probs\n",
    "                #start probs = prob word has tag t * prob that tag t is at start\n",
    "                \n",
    "                sprob = pairprob['START'].probs \n",
    "                for j in range(0, lentags):                    \n",
    "                    trell.prev[j].prob = sprob[tags[j]]+ wprobs[w][tags[j]] \n",
    "                    \n",
    "            # deafling with last word\n",
    "            elif i==(len(sent)-2):\n",
    "                \n",
    "                trell.curr = calctrelnodes(trell.prev,wprobs[w], tags, pairprob)\n",
    "                for j in range(0,len(tags)):                    \n",
    "                    trell.curr[j].prob = trell.curr[j].prob + endprobs[tags[j]]\n",
    "                trell.update()\n",
    "                \n",
    "            else:\n",
    "            #dealing with the second word onwards \n",
    "                trell.curr = calctrelnodes(trell.prev,wprobs[w], tags, pairprob)                \n",
    "                trell.update()\n",
    "                    \n",
    "#         now done dealing with all words return greatest\n",
    "        mprob = -100000\n",
    "        path = []\n",
    "        for i in range(0, len(tags)):\n",
    "            n = trell.curr[i]\n",
    "            if n.prob > mprob:\n",
    "                mprob = n.prob\n",
    "                pat=[]\n",
    "                pat.extend(n.path)\n",
    "                pat.append(tags[i])\n",
    "                path = pat\n",
    "                \n",
    "        out = [('START', 'START')]\n",
    "        \n",
    "        for i in range(0, len(path)):            \n",
    "            out.append((sent[i+1], path[i]))\n",
    "            \n",
    "        out.append(('END', 'END'))\n",
    "        for n in unseennum:          \n",
    "            out[n] = (out[n][0],'NUM')\n",
    "        for n in unseenadj:\n",
    "            out[n]= (out[n][0], 'ADJ')\n",
    "        \n",
    "        output.append(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
